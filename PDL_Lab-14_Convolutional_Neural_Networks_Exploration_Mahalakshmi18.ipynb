{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Jq8mI-ThfvO"
   },
   "source": [
    "# 205229118\n",
    "# Mahalakshmi S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOCeWxTthfvR"
   },
   "source": [
    "# Lab14: Convolutional Neural Networks Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzgM_KcdwhUv"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuDZ7zy1CdsZ"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPMd2qwBwpro"
   },
   "source": [
    "# Load your data and print the shape of training and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztYGpP3RhfvW",
    "outputId": "1ae88732-cc41-4f25-cfc0-53c2eaee2b8d"
   },
   "outputs": [],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cVEqP_OhfvY",
    "outputId": "7baa4dca-6b58-4406-8ac4-9004c41cb920"
   },
   "outputs": [],
   "source": [
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEKviNeIhfvZ",
    "outputId": "552b3e3a-c749-42f8-eeed-6ff9dd76cb4c"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape[0], 'train samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDqb8hsOhfva",
    "outputId": "b9b26b1d-0b1d-4632-8ea7-ce31f415f69d"
   },
   "outputs": [],
   "source": [
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "SnKQ9_zzicyz",
    "outputId": "4265cdcb-115c-4254-9f90-632db1d7eb9a"
   },
   "outputs": [],
   "source": [
    "plt.matshow(x_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJJ4RjePic1r"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize to 0 to 1 range\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fv-KwDDxjDw_"
   },
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6R3uLuc8jnxz"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "x_test = x_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cteCqkQkwf9s",
    "outputId": "51efabbb-2629-4992-c79b-0affe19077c8"
   },
   "outputs": [],
   "source": [
    "y_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4yFdqPjqj0Ww",
    "outputId": "08c3a826-e7d8-43b5-92c4-62df13823198"
   },
   "outputs": [],
   "source": [
    "np.argmin(y_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS47g2Vz08NK"
   },
   "source": [
    "## 1. Number of filters: Run CNN with 1 convolution hidden layer (32 filters of 3*3), flatten layer and output layer, (with any activation function and any optimizer) for 5 epochs. Change number of filters as 4, 32, 128, 512, 2056. What is the training and testing accuracies? Print the number of parameters of the model and training time for each of these configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5iBWUs00zMZ"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=4,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLvIQclV_d7Z",
    "outputId": "4827b4de-638e-415c-fb5a-5d1a334b4c7c"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqGY1o4P26pk"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(x_train , y_train , batch_size=batch_size ,validation_data=(x_test,y_test),epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wOGXNvchfvj",
    "outputId": "ffbe6489-9eee-4a9f-92cc-4b73b5ee3652"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "8ZyLOBZThfvj",
    "outputId": "72d7fbfe-df3d-4b7d-f229-97642f61b57c"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "GkqDI0_Jhfvk",
    "outputId": "d7c5cc39-4f7a-478b-b576-f1a2bf81b4e5"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLGbcGCnhfvl"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Conv2D(filters=32,kernel_size=(3,3),activation='sigmoid',input_shape=(28, 28, 1)))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='sigmoid'))\n",
    "model3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MC1eh_PQhfvm",
    "outputId": "16e9f498-9fa8-4fba-8fa1-654269ec069a"
   },
   "outputs": [],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZj8wID9hfvm"
   },
   "outputs": [],
   "source": [
    "model3.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBewoG3Phfvn",
    "outputId": "458c26f8-43da-4d9f-a1ba-8843ae69c389"
   },
   "outputs": [],
   "source": [
    "history3=model3.fit(x_train , y_train , batch_size=batch_size, validation_data=(x_test,y_test) , epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viYPoTyohfvn"
   },
   "outputs": [],
   "source": [
    "score3 = model3.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWseYlHwhfvo",
    "outputId": "821c1532-7312-4b33-f91b-e409cf7db4e5"
   },
   "outputs": [],
   "source": [
    "plt.plot(history3.history['accuracy'])\n",
    "plt.plot(history3.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swHX_p-9hfvp",
    "outputId": "ba462290-f85a-4d29-f233-04d24366b13d"
   },
   "outputs": [],
   "source": [
    "plt.plot(history3.history['loss'])\n",
    "plt.plot(history3.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnsAQhZGhfvq"
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Conv2D(filters=128,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(64, activation='tanh'))\n",
    "model5.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pehM-D-Shfvr"
   },
   "outputs": [],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QK9jtq50hfvs"
   },
   "outputs": [],
   "source": [
    "model5.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history5=model5.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZeG1qPehfvt"
   },
   "outputs": [],
   "source": [
    "score5 = model5.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score5[0])\n",
    "print('Test accuracy:', score5[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNv6lcS7hfvt"
   },
   "outputs": [],
   "source": [
    "plt.plot(history5.history['accuracy'])\n",
    "plt.plot(history5.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y1i--DThfvu"
   },
   "outputs": [],
   "source": [
    "plt.plot(history5.history['loss'])\n",
    "plt.plot(history5.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_Gmio0jhfvu"
   },
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Conv2D(filters=512,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(64, activation='sigmoid'))\n",
    "model7.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zTJHtr9hfvu"
   },
   "outputs": [],
   "source": [
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlOid_Kbhfvv"
   },
   "outputs": [],
   "source": [
    "model7.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_wZoaBihfvv"
   },
   "outputs": [],
   "source": [
    "history7=model7.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6jDHAoyhfvv"
   },
   "outputs": [],
   "source": [
    "score7 = model7.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score7[0])\n",
    "print('Test accuracy:', score7[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akhsZGgohfvw"
   },
   "outputs": [],
   "source": [
    "plt.plot(history7.history['accuracy'])\n",
    "plt.plot(history7.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtndHzFShfvw"
   },
   "outputs": [],
   "source": [
    "plt.plot(history7.history['loss'])\n",
    "plt.plot(history7.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5ic72Cahfvx"
   },
   "outputs": [],
   "source": [
    "model9= Sequential()\n",
    "model9.add(Conv2D(filters=2056,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model9.add(Flatten())\n",
    "model9.add(Dense(64, activation='sigmoid'))\n",
    "model9.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bb6WtQahfvx"
   },
   "outputs": [],
   "source": [
    "model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3A2kN95hfvx"
   },
   "outputs": [],
   "source": [
    "model9.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoPS5kL1hfvy"
   },
   "outputs": [],
   "source": [
    "history9=model9.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sRKfG1v5hfvy"
   },
   "outputs": [],
   "source": [
    "score9 = model9.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score9[0])\n",
    "print('Test accuracy:', score9[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZBUm4fMhfvy"
   },
   "outputs": [],
   "source": [
    "plt.plot(history9.history['accuracy'])\n",
    "plt.plot(history9.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zr3SfOVqhfvz"
   },
   "outputs": [],
   "source": [
    "plt.plot(history9.history['loss'])\n",
    "plt.plot(history9.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model with 4 filters')\n",
    "print('Train accuracy:',history.history['accuracy'][4])\n",
    "score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print('***********************************************')\n",
    "print('model3 with 32 filters')\n",
    "print('Train accuracy:',history3.history['accuracy'][4])\n",
    "score1 = model3.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score3[0])\n",
    "print('Test accuracy:', score3[1])\n",
    "print('***********************************************')\n",
    "print('model5 with 128 filters')\n",
    "print('Train accuracy:',history5.history['accuracy'][4])\n",
    "score5 = model5.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score5[0])\n",
    "print('Test accuracy:', score5[1])\n",
    "print('***********************************************')\n",
    "print('model7 with 512 filters')\n",
    "print('Train accuracy:',history7.history['accuracy'][4])\n",
    "score7 = model7.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score7[0])\n",
    "print('Test accuracy:', score7[1])\n",
    "print('***********************************************')\n",
    "print('model9 with 2056 filters')\n",
    "print('Train accuracy:',history9.history['accuracy'][4])\n",
    "score9 = model9.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score9[0])\n",
    "print('Test accuracy:', score9[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A_rbEZ12hfvz"
   },
   "source": [
    "## 2. Number of Layers: Run CNN with 1 convolution hidden layer (32 filters of 3*3), flatten layer and output layer, (with any activation function and any optimizer) for 5 epochs. Change number of convolutional layers as 2, 3, 4. What is the training and testing accuracies? Print the number of parameters of the model and training time for each of these configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2a14eAV8Qbw"
   },
   "outputs": [],
   "source": [
    "model11 = Sequential()\n",
    "model11.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model11.add(Flatten())\n",
    "model11.add(Dense(64, activation='relu'))\n",
    "model11.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1S-rK2N0AJ-5",
    "outputId": "0cc0dc92-425a-4cc4-c499-238dba63c112"
   },
   "outputs": [],
   "source": [
    "model11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEB3VB5-BfSa"
   },
   "outputs": [],
   "source": [
    "model11.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lc5dsGivhfv0",
    "outputId": "d359b780-6fbf-4fd7-eea8-23b144a165ab"
   },
   "outputs": [],
   "source": [
    "history11=model11.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebyjRWeohfv0",
    "outputId": "6367ac85-74d8-41cc-e7d0-c4a104af8320"
   },
   "outputs": [],
   "source": [
    "score11 = model11.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score11[0])\n",
    "print('Test accuracy:', score11[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip2tUMrVhfv0",
    "outputId": "c8b57deb-7e49-40e3-bca1-654ea4265a45"
   },
   "outputs": [],
   "source": [
    "plt.plot(history11.history['accuracy'])\n",
    "plt.plot(history11.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpOYd4z_hfv1",
    "outputId": "c0182b46-0b4f-4631-95c2-5b479deb05e1"
   },
   "outputs": [],
   "source": [
    "plt.plot(history11.history['loss'])\n",
    "plt.plot(history11.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9F7mT3OlCXYe"
   },
   "outputs": [],
   "source": [
    "model13 = Sequential()\n",
    "model13.add(Conv2D(filters=32,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model13.add(Conv2D(filters=32,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model13.add(Flatten())\n",
    "model13.add(Dense(64, activation='relu'))\n",
    "model13.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqPO__ozhfv1",
    "outputId": "f9c93bd5-e8b0-4a34-d293-06d19d05c31d"
   },
   "outputs": [],
   "source": [
    "model13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HNgekbmhfv1"
   },
   "outputs": [],
   "source": [
    "model13.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LX0qLG4hJBes",
    "outputId": "4e2cd695-adc0-4d98-e239-8ecdc1db2c79"
   },
   "outputs": [],
   "source": [
    "history13=model13.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wo2BQvBShfv2",
    "outputId": "d3a84012-b12c-47ac-bda6-0dde80d330c8"
   },
   "outputs": [],
   "source": [
    "score13 = model13.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score13[0])\n",
    "print('Test accuracy:', score13[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XurH4DEShfv2",
    "outputId": "7c8fdce0-539f-4264-ed42-d15f952c0ce0"
   },
   "outputs": [],
   "source": [
    "plt.plot(history13.history['accuracy'])\n",
    "plt.plot(history13.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwpuHPL_hfv2",
    "outputId": "12273843-4fbb-47fe-e908-426d0a6753c1"
   },
   "outputs": [],
   "source": [
    "plt.plot(history13.history['loss'])\n",
    "plt.plot(history13.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH1RZAiZhfv3"
   },
   "outputs": [],
   "source": [
    "model15 = Sequential()\n",
    "model15.add(Conv2D(filters=32,kernel_size=(3,3),activation='sigmoid',input_shape=(28, 28, 1)))\n",
    "model15.add(Conv2D(filters=32,kernel_size=(3,3),activation='sigmoid',input_shape=(28, 28, 1)))\n",
    "model15.add(Conv2D(filters=32,kernel_size=(3,3),activation='sigmoid',input_shape=(28, 28, 1)))\n",
    "model15.add(Flatten())\n",
    "model15.add(Dense(64, activation='relu'))\n",
    "model15.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Lq9xKdfhfv3"
   },
   "outputs": [],
   "source": [
    "model15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6jXgIpuhfv3"
   },
   "outputs": [],
   "source": [
    "model15.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2w-HKmVShfv3"
   },
   "outputs": [],
   "source": [
    "history15=model15.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ph7pJtg-hfv3"
   },
   "outputs": [],
   "source": [
    "score15 = model15.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score15[0])\n",
    "print('Test accuracy:', score15[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMB1FjPrhfv4"
   },
   "outputs": [],
   "source": [
    "plt.plot(history15.history['accuracy'])\n",
    "plt.plot(history15.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcqkAfsnhfv4"
   },
   "outputs": [],
   "source": [
    "plt.plot(history15.history['loss'])\n",
    "plt.plot(history15.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JSmOLLEhfv4"
   },
   "outputs": [],
   "source": [
    "model17 = Sequential()\n",
    "model17.add(Conv2D(filters=32,kernel_size=(3,3),activation='sigmoid',input_shape=(28, 28, 1)))\n",
    "model17.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model17.add(Conv2D(filters=32,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model17.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model17.add(Flatten())\n",
    "model17.add(Dense(64, activation='tanh'))\n",
    "model17.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Doktj9BVhfv5"
   },
   "outputs": [],
   "source": [
    "model17.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IppwpQcWhfv5"
   },
   "outputs": [],
   "source": [
    "model17.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6dy4J2bBhfv5"
   },
   "outputs": [],
   "source": [
    "history17=model17.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRbWAie5hfv5"
   },
   "outputs": [],
   "source": [
    "score17 = model17.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score17[0])\n",
    "print('Test accuracy:', score17[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ff4QLH1hfv6"
   },
   "outputs": [],
   "source": [
    "plt.plot(history17.history['accuracy'])\n",
    "plt.plot(history17.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZBGFQLthfv6"
   },
   "outputs": [],
   "source": [
    "plt.plot(history17.history['loss'])\n",
    "plt.plot(history17.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model11 with 1 filters')\n",
    "print('Train accuracy:',history11.history['accuracy'][4])\n",
    "score11 = model11.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score11[0])\n",
    "print('Test accuracy:', score11[1])\n",
    "print('***********************************************')\n",
    "print('model13 with 2 filters')\n",
    "print('Train accuracy:',history13.history['accuracy'][4])\n",
    "score13 = model13.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score13[0])\n",
    "print('Test accuracy:', score13[1])\n",
    "print('***********************************************')\n",
    "print('model with 3 filters')\n",
    "print('Train accuracy:',history15.history['accuracy'][4])\n",
    "score15 = model15.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score15[0])\n",
    "print('Test accuracy:', score15[1])\n",
    "print('***********************************************')\n",
    "print('model with 4 filters')\n",
    "print('Train accuracy:',history17.history['accuracy'][4])\n",
    "score17 = model17.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score17[0])\n",
    "print('Test accuracy:', score17[1])\n",
    "print('***********************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrgTDLhLhfv6"
   },
   "source": [
    "## 3. Size of Filters: Run CNN with 2 convolution layer (16 filters of 3*3 filter, each layer), flatten layer and output layer (with any activation function and any optimizer) for 5 epochs. Run the same architecture with different sizes of filters as 5*5 and 7*7. What is the training and testing accuracies? Print the number of parameters of the model and training time for each of these configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUtVPNiehfv6"
   },
   "outputs": [],
   "source": [
    "model19 = Sequential()\n",
    "model19.add(Conv2D(filters=16,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model19.add(Conv2D(filters=16,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model19.add(Flatten())\n",
    "model19.add(Dense(64, activation='relu'))\n",
    "model19.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLoTQvoFhfv6"
   },
   "outputs": [],
   "source": [
    "model19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XRfVGQvhfv7"
   },
   "outputs": [],
   "source": [
    "model19.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmVQmGbdhfv7"
   },
   "outputs": [],
   "source": [
    "history19=model19.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdqLH6cvhfv7"
   },
   "outputs": [],
   "source": [
    "score19 = model19.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score19[0])\n",
    "print('Test accuracy:', score19[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jS8M3Rhchfv7"
   },
   "outputs": [],
   "source": [
    "plt.plot(history19.history['accuracy'])\n",
    "plt.plot(history19.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGwxLYGRhfv7"
   },
   "outputs": [],
   "source": [
    "plt.plot(history19.history['loss'])\n",
    "plt.plot(history19.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTSaYarshfwA"
   },
   "outputs": [],
   "source": [
    "plt.plot(history23.history['accuracy'])\n",
    "plt.plot(history23.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMwy7pMOhfwA"
   },
   "outputs": [],
   "source": [
    "plt.plot(history23.history['loss'])\n",
    "plt.plot(history23.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model with 3*3 filters')\n",
    "print('Train accuracy:',history19.history['accuracy'][4])\n",
    "score19 = model19.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score19[0])\n",
    "print('Test accuracy:', score19[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ue88IvGhfwA"
   },
   "source": [
    "## 4. Activation function: Run CNN with 2 convolution layer (16 filters of 3*3 filter, each layer), flatten layer and output layer (with any optimizer) with sigmoid activation function for all layers, for 5 epochs. Change only the activation function as tanh, relu (for all layers) etc. What is the training and testing accuracies? Run the same models for 10 epochs. Any changes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iL6_1u9whfwB"
   },
   "outputs": [],
   "source": [
    "model25 = Sequential()\n",
    "model25.add(Conv2D(filters=16,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model25.add(Conv2D(filters=16,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model25.add(Flatten())\n",
    "model25.add(Dense(64, activation='relu'))\n",
    "model25.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIL3xVN-hfwB"
   },
   "outputs": [],
   "source": [
    "model25.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5B8oZ08hfwB"
   },
   "outputs": [],
   "source": [
    "model25.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SylBGfEzhfwB"
   },
   "outputs": [],
   "source": [
    "history25=model25.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "srKQtdjMhfwB"
   },
   "outputs": [],
   "source": [
    "score25 = model25.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score25[0])\n",
    "print('Test accuracy:', score25[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2XNcql6hfwC"
   },
   "outputs": [],
   "source": [
    "plt.plot(history25.history['accuracy'])\n",
    "plt.plot(history25.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1I-RNXqQhfwC"
   },
   "outputs": [],
   "source": [
    "plt.plot(history25.history['loss'])\n",
    "plt.plot(history25.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model25 with tanh activation')\n",
    "print('Train accuracy:',history25.history['accuracy'][4])\n",
    "score25 = model25.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score25[0])\n",
    "print('Test accuracy:', score25[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIALzUlChfwF"
   },
   "source": [
    "## 5. Filter Size combinations: For the 2 convolution layers use different combinations of filter sizes such as layer 1: 3*3, layer 2: 5*5. There can be lot of combinations like this. Which one is the best for 2 conv layer each with 16 filter architecture? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ma67MROhfwF"
   },
   "outputs": [],
   "source": [
    "model31 = Sequential()\n",
    "model31.add(Conv2D(filters=16, kernel_size=(3,3), activation='sigmoid', input_shape=(28,28,1)))\n",
    "model31.add(Conv2D(filters=16, kernel_size=(5,5), activation='sigmoid', input_shape=(28,28,1)))\n",
    "model31.add(Flatten())\n",
    "model31.add(Dense(64, activation='relu'))\n",
    "model31.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mz6jjBO_hfwF"
   },
   "outputs": [],
   "source": [
    "model31.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-5o8H02hfwF"
   },
   "outputs": [],
   "source": [
    "model31.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLNX63jZhfwG"
   },
   "outputs": [],
   "source": [
    "history31=model31.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BECf27FVhfwG"
   },
   "outputs": [],
   "source": [
    "score31 = model31.evaluate(x_test, y_test,verbose=2)\n",
    "print('Test loss:', score31[0])\n",
    "print('Test accuracy:', score31[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kuve_oaYhfwG"
   },
   "outputs": [],
   "source": [
    "plt.plot(history31.history['accuracy'])\n",
    "plt.plot(history31.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNso5oGohfwG"
   },
   "outputs": [],
   "source": [
    "plt.plot(history31.history['loss'])\n",
    "plt.plot(history31.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model31 with filter size 3 and 5')\n",
    "print('Train accuracy:',history31.history['accuracy'][4])\n",
    "score31 = model31.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score31[0])\n",
    "print('Test accuracy:', score31[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACPV4vlUhfwI"
   },
   "source": [
    "## 6. Layer-filter combinations: Run different CNN models mimicking the following structures. i.e. increase the number of filters or decrease the number of filters etc. Which one gives best accuracy? Print the number of parameters of the model and training time for each of these configurations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I choosen ConfigurationB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VrmjSDMhfwI"
   },
   "outputs": [],
   "source": [
    "model35 = Sequential()\n",
    "model35.add(Conv2D(filters=16,kernel_size=(3,3),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model35.add(Flatten())\n",
    "model35.add(Dense(64, activation='sigmoid'))\n",
    "model35.add(Dense(256, activation='sigmoid'))\n",
    "model35.add(Dense(512, activation='sigmoid'))\n",
    "model35.add(Dense(128, activation='sigmoid'))\n",
    "model35.add(Dense(32, activation='sigmoid'))\n",
    "model35.add(Dense(16, activation='sigmoid'))\n",
    "model35.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W21KVS__hfwJ"
   },
   "outputs": [],
   "source": [
    "model35.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIJrwVIZhfwJ"
   },
   "outputs": [],
   "source": [
    "model35.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUzbVjt-hfwJ"
   },
   "outputs": [],
   "source": [
    "history35=model.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCeDgIvUhfwJ"
   },
   "outputs": [],
   "source": [
    "score35 = model35.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score35[0])\n",
    "print('Test accuracy:', score35[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PIvCUyFhfwJ"
   },
   "outputs": [],
   "source": [
    "plt.plot(history35.history['accuracy'])\n",
    "plt.plot(history35.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t0cvs8ThfwJ"
   },
   "outputs": [],
   "source": [
    "plt.plot(history35.history['loss'])\n",
    "plt.plot(history35.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model35 with combinationB layer filter\")\n",
    "print('Train accuracy:',history35.history['accuracy'][4])\n",
    "score35 = model35.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score35[0])\n",
    "print('Test accuracy:', score35[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfbRZ4JahfwQ"
   },
   "source": [
    "## 7. Influence of Striding: Run CNN with 2 conv layer, 32 filters each of size 3*3 filters, flatten layer and output layer with any optimizer with relu activation function for all layers, for 5 epochs. Run the same model with striding 2, 3 etc. What is the training and testing accuracies? Print the number of parameters of the model and training time for each of these configurations. Run same setup for different size of filters such as 5*5 and 7*7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fNQwZA_hfwQ"
   },
   "outputs": [],
   "source": [
    "model43 = Sequential()\n",
    "model43.add(Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model43.add(Conv2D(filters=32,kernel_size=(3,3),strides=(2,2),activation='tanh',input_shape=(28, 28, 1)))\n",
    "model43.add(Flatten())\n",
    "model43.add(Dense(64, activation='relu'))\n",
    "model43.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K5b5khXwhfwQ"
   },
   "outputs": [],
   "source": [
    "model43.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMe2CORzhfwR"
   },
   "outputs": [],
   "source": [
    "model43.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYGzkIXXhfwR"
   },
   "outputs": [],
   "source": [
    "history43=model43.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUBzh8U7hfwR"
   },
   "outputs": [],
   "source": [
    "score43 = model43.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score43[0])\n",
    "print('Test accuracy:', score43[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMpBo6AihfwR"
   },
   "outputs": [],
   "source": [
    "plt.plot(history43.history['accuracy'])\n",
    "plt.plot(history43.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35uQjMvXhfwT"
   },
   "outputs": [],
   "source": [
    "plt.plot(history43.history['loss'])\n",
    "plt.plot(history43.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model43 with 3filter,2strides')\n",
    "print('Train accuracy:',history43.history['accuracy'][4])\n",
    "score43 = model43.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score43[0])\n",
    "print('Test accuracy:', score43[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G_fZuS_hfwV"
   },
   "source": [
    "## 8. Influence of Padding: Run CNN with 2 conv layer, 32 filters each of size 3*3 filters, flatten layer and output layer with any optimizer with relu activation function for all layers, for 5 epochs. Run the same model with padding. What is the training and testing accuracies? Print the number of parameters of the model and training time for each of these configurations. Run same setup with padding for different size of filters such as 5*5 and 7*7 also. Print your analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttplfrE-hfwW"
   },
   "outputs": [],
   "source": [
    "model49 = Sequential()\n",
    "model49.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(28, 28, 1)))\n",
    "model49.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',padding='same',input_shape=(28, 28, 1)))\n",
    "model49.add(Flatten())\n",
    "model49.add(Dense(64, activation='relu'))\n",
    "model49.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tirJbKTnhfwW"
   },
   "outputs": [],
   "source": [
    "model49.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOlqtq2mhfwW"
   },
   "outputs": [],
   "source": [
    "model49.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vxpu5lGKhfwW"
   },
   "outputs": [],
   "source": [
    "history49=model49.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVEl9PTvhfwX"
   },
   "outputs": [],
   "source": [
    "score49 = model49.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score49[0])\n",
    "print('Test accuracy:', score49[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYzjwceBhfwX"
   },
   "outputs": [],
   "source": [
    "plt.plot(history49.history['accuracy'])\n",
    "plt.plot(history49.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZC6cSjMXhfwX"
   },
   "outputs": [],
   "source": [
    "plt.plot(history49.history['loss'])\n",
    "plt.plot(history49.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model49 with 3filter size same padding')\n",
    "print('Train accuracy:',history49.history['accuracy'][4])\n",
    "score49 = model49.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score49[0])\n",
    "print('Test accuracy:', score49[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOH-s4FWhfwb"
   },
   "source": [
    "## 9. Influence of Pooling: Run CNN with 2 conv layer, 32 filters each of size 3*3 filters, flatten layer and output layer with any optimizer with relu activation function for all layers, for 5 epochs. Run the same model with pooling 2*2, 3*3 etc. What is the training and testing accuracies? Print the number of parameters of the model and training time for each of these configurations. Run same setup with different pooling sizes for different size of filters such as 5*5 and 7*7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tq3xJyaKhfwb"
   },
   "outputs": [],
   "source": [
    "model55 = Sequential()\n",
    "model55.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model55.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model55.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model55.add(Flatten())\n",
    "model55.add(Dense(64, activation='relu'))\n",
    "model55.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7QY-D1tyhfwb"
   },
   "outputs": [],
   "source": [
    "model55.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Z6Q0k4Rhfwb"
   },
   "outputs": [],
   "source": [
    "model55.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=RMSprop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pH_IdPJLhfwc"
   },
   "outputs": [],
   "source": [
    "history55=model55.fit(x_train , y_train , batch_size=batch_size , validation_data=(x_test,y_test), epochs= 5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmQCvlZxhfwc"
   },
   "outputs": [],
   "source": [
    "score55 = model55.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score55[0])\n",
    "print('Test accuracy:', score55[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xgswdTkhfwc"
   },
   "outputs": [],
   "source": [
    "plt.plot(history55.history['accuracy'])\n",
    "plt.plot(history55.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgy4xZB7hfwc"
   },
   "outputs": [],
   "source": [
    "plt.plot(history55.history['loss'])\n",
    "plt.plot(history55.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('model55 with 3filter size  2polling')\n",
    "print('Train accuracy:',history55.history['accuracy'][4])\n",
    "score55 = model55.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', score55[0])\n",
    "print('Test accuracy:', score55[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PDL_Lab-14_Convolutional_Neural_Networks_Exploration_Mahalakshmi18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
